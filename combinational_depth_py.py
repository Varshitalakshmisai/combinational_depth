# -*- coding: utf-8 -*-
"""Combinational_Depth.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10HmW7_pO-mLAvd3D4Nz1lAIXBbPeYn6n
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Step 1: Install Dependencies**

Install required Python libraries:
"""

!pip install torch torchvision torchaudio torch-geometric networkx PyVerilog scikit-learn tqdm matplotlib

"""**Step 2: Download & Load OpenABC-D Dataset**"""

import os
import urllib.request
import zipfile

dataset_url = "https://github.com/NYU-MLDA/OpenABC/archive/refs/heads/main.zip"
dataset_path = "OpenABC-D.zip"

if not os.path.exists(dataset_path):
    print("Downloading OpenABC-D dataset...")
    urllib.request.urlretrieve(dataset_url, dataset_path)

with zipfile.ZipFile(dataset_path, "r") as zip_ref:
    zip_ref.extractall("OpenABC-D")

print("Dataset downloaded and extracted")

"""**Step 3: Parse RTL Code & Convert to Graph Representation**"""

import networkx as nx
import glob
from pyverilog.vparser.parser import parse

def parse_rtl_to_graph(rtl_file):
    ast, _ = parse([rtl_file])
    graph = nx.DiGraph()

    def traverse(node):
        if node is None:
            return
        if hasattr(node, "children"):
            for child in node.children():
                traverse(child)
        if node.__class__.__name__ == "Instance":
            module_name = node.module
            instance_name = node.name
            graph.add_node(instance_name, type=module_name)

    traverse(ast)
    return graph

verilog_files = glob.glob("OpenABC-D/OpenABC-main/dataset/*.v")
graph = parse_rtl_to_graph(verilog_files[0])

print(f"Parsed {len(graph.nodes)} gates and {len(graph.edges)} connections")

"""**Step 4: Compute Combinational Depth**"""

def compute_combinational_depth(graph):
    if not nx.is_directed_acyclic_graph(graph):
        raise ValueError("Graph is not a DAG!")

    depth = 0
    for node in nx.topological_sort(graph):
        predecessors = list(graph.predecessors(node))
        graph.nodes[node]['depth'] = max([graph.nodes[p]['depth'] for p in predecessors], default=0) + 1
        depth = max(depth, graph.nodes[node]['depth'])

    return depth

depth = compute_combinational_depth(graph)
print(f"Computed Combinational Depth: {depth}")

"""**Step 5: Convert Graph into Features for GNN**"""

import torch
from torch_geometric.data import Data

def convert_graph_to_torch(graph):
    node_features = torch.tensor([graph.nodes[node]['depth'] for node in graph.nodes], dtype=torch.float)
    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()
    return Data(x=node_features.view(-1, 1), edge_index=edge_index)

graph_data = convert_graph_to_torch(graph)
print(graph_data)

"""***Step 6: Define GNN Model**"""

import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(GNNModel, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, 1)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = F.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x.view(-1)

model = GNNModel(input_dim=1, hidden_dim=64)
print(model)

"""**Step 7: Train the Model**"""

import torch.optim as optim
from torch.utils.data import DataLoader

epochs = 50
lr = 0.01
optimizer = optim.Adam(model.parameters(), lr=lr)
loss_fn = nn.MSELoss()

def train(model, data, epochs):
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(data)
        loss = loss_fn(output, data.x.squeeze())
        loss.backward()
        optimizer.step()
        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Loss = {loss.item():.4f}")

train(model, graph_data, epochs=50)

"""**Step 8:Test the model**"""

model.eval()
predicted_depths = model(graph_data).detach().numpy()
print(f"Predicted combinational depth: {predicted_depths.max():.2f}")